"""
AIå†³ç­–è°ƒè¯•å·¥å…·
æä¾›è¯¦ç»†çš„AIå†³ç­–è¿‡ç¨‹åˆ†æå’Œæ€§èƒ½ç›‘æ§
"""
import time
import json
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from pathlib import Path
import logging

from .strategies.base import AIAction, ActionType, GameContext

logger = logging.getLogger(__name__)


@dataclass
class DecisionRecord:
    """å†³ç­–è®°å½•"""
    timestamp: float
    game_id: str
    turn_number: int
    strategy_name: str
    action_type: str
    confidence: float
    reasoning: str
    execution_time: float
    game_state_snapshot: Dict[str, Any]
    llm_interaction: Optional[Dict[str, Any]] = None


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    total_decisions: int = 0
    successful_decisions: int = 0
    average_execution_time: float = 0.0
    confidence_distribution: Dict[str, int] = None
    action_type_distribution: Dict[str, int] = None
    strategy_performance: Dict[str, Dict[str, Any]] = None

    def __post_init__(self):
        if self.confidence_distribution is None:
            self.confidence_distribution = {
                "high (>0.8)": 0,
                "medium (0.5-0.8)": 0,
                "low (<0.5)": 0
            }
        if self.action_type_distribution is None:
            self.action_type_distribution = {action.value: 0 for action in ActionType}
        if self.strategy_performance is None:
            self.strategy_performance = {}


class AIDebugger:
    """AIå†³ç­–è°ƒè¯•å™¨"""

    def __init__(self, log_file: str = "ai_decisions.json"):
        self.log_file = Path(log_file)
        self.decision_history: List[DecisionRecord] = []
        self.current_session_start = time.time()
        self.performance_metrics = PerformanceMetrics()

        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        self.log_file.parent.mkdir(exist_ok=True)

        logger.info("ğŸ”§ AIè°ƒè¯•å™¨å·²åˆå§‹åŒ–")

    def record_decision(self, action: AIAction, strategy_name: str,
                       context: GameContext, llm_data: Optional[Dict[str, Any]] = None):
        """è®°å½•AIå†³ç­–"""
        record = DecisionRecord(
            timestamp=time.time(),
            game_id=context.game_id,
            turn_number=context.turn_number,
            strategy_name=strategy_name,
            action_type=action.action_type.value,
            confidence=action.confidence,
            reasoning=action.reasoning,
            execution_time=action.execution_time,
            game_state_snapshot=self._create_game_state_snapshot(context),
            llm_interaction=llm_data
        )

        self.decision_history.append(record)
        self._update_performance_metrics(record)

        logger.info(f"ğŸ“ è®°å½•å†³ç­–: {strategy_name} -> {action.action_type.value}")

    def _create_game_state_snapshot(self, context: GameContext) -> Dict[str, Any]:
        """åˆ›å»ºæ¸¸æˆçŠ¶æ€å¿«ç…§"""
        return {
            "player_health": context.player_health,
            "opponent_health": context.opponent_health,
            "player_mana": context.player_mana,
            "opponent_mana": context.opponent_mana,
            "hand_count": len(context.player_hand),
            "player_field_count": len(context.player_field),
            "opponent_field_count": len(context.opponent_field),
            "turn_number": context.turn_number,
            "phase": context.phase
        }

    def _update_performance_metrics(self, record: DecisionRecord):
        """æ›´æ–°æ€§èƒ½æŒ‡æ ‡"""
        self.performance_metrics.total_decisions += 1
        self.performance_metrics.successful_decisions += 1

        # æ›´æ–°å¹³å‡æ‰§è¡Œæ—¶é—´
        total_time = (self.performance_metrics.average_execution_time *
                     (self.performance_metrics.total_decisions - 1) + record.execution_time)
        self.performance_metrics.average_execution_time = total_time / self.performance_metrics.total_decisions

        # æ›´æ–°ç½®ä¿¡åº¦åˆ†å¸ƒ
        if record.confidence > 0.8:
            self.performance_metrics.confidence_distribution["high (>0.8)"] += 1
        elif record.confidence >= 0.5:
            self.performance_metrics.confidence_distribution["medium (0.5-0.8)"] += 1
        else:
            self.performance_metrics.confidence_distribution["low (<0.5)"] += 1

        # æ›´æ–°åŠ¨ä½œç±»å‹åˆ†å¸ƒ
        self.performance_metrics.action_type_distribution[record.action_type] += 1

        # æ›´æ–°ç­–ç•¥æ€§èƒ½
        if record.strategy_name not in self.performance_metrics.strategy_performance:
            self.performance_metrics.strategy_performance[record.strategy_name] = {
                "decisions": 0,
                "avg_confidence": 0.0,
                "avg_time": 0.0,
                "actions": {}
            }

        strategy_stats = self.performance_metrics.strategy_performance[record.strategy_name]
        strategy_stats["decisions"] += 1

        # æ›´æ–°ç­–ç•¥å¹³å‡ç½®ä¿¡åº¦
        old_avg = strategy_stats["avg_confidence"]
        count = strategy_stats["decisions"]
        strategy_stats["avg_confidence"] = (old_avg * (count - 1) + record.confidence) / count

        # æ›´æ–°ç­–ç•¥å¹³å‡æ—¶é—´
        old_time = strategy_stats["avg_time"]
        strategy_stats["avg_time"] = (old_time * (count - 1) + record.execution_time) / count

        # æ›´æ–°ç­–ç•¥åŠ¨ä½œåˆ†å¸ƒ
        if record.action_type not in strategy_stats["actions"]:
            strategy_stats["actions"][record.action_type] = 0
        strategy_stats["actions"][record.action_type] += 1

    def analyze_decision_patterns(self) -> Dict[str, Any]:
        """åˆ†æå†³ç­–æ¨¡å¼"""
        if not self.decision_history:
            return {"message": "æš‚æ— å†³ç­–æ•°æ®"}

        # åˆ†ææœ€è¿‘çš„å†³ç­–è¶‹åŠ¿
        recent_decisions = self.decision_history[-20:]  # æœ€è¿‘20ä¸ªå†³ç­–

        # æŒ‰ç­–ç•¥åˆ†æ
        strategy_analysis = {}
        for record in recent_decisions:
            strategy = record.strategy_name
            if strategy not in strategy_analysis:
                strategy_analysis[strategy] = {
                    "count": 0,
                    "avg_confidence": 0.0,
                    "avg_time": 0.0,
                    "common_actions": {}
                }

            stats = strategy_analysis[strategy]
            stats["count"] += 1
            stats["avg_confidence"] = (stats["avg_confidence"] * (stats["count"] - 1) + record.confidence) / stats["count"]
            stats["avg_time"] = (stats["avg_time"] * (stats["count"] - 1) + record.execution_time) / stats["count"]

            action = record.action_type
            if action not in stats["common_actions"]:
                stats["common_actions"][action] = 0
            stats["common_actions"][action] += 1

        # åˆ†ææ—¶é—´è¶‹åŠ¿
        time_analysis = {
            "avg_decision_time": sum(r.execution_time for r in recent_decisions) / len(recent_decisions),
            "slowest_decision": max(recent_decisions, key=lambda r: r.execution_time),
            "fastest_decision": min(recent_decisions, key=lambda r: r.execution_time)
        }

        # åˆ†æç½®ä¿¡åº¦è¶‹åŠ¿
        confidence_trend = [record.confidence for record in recent_decisions]
        confidence_analysis = {
            "avg_confidence": sum(confidence_trend) / len(confidence_trend),
            "confidence_trend": "increasing" if len(confidence_trend) > 1 and confidence_trend[-1] > confidence_trend[0] else "stable",
            "high_confidence_ratio": sum(1 for c in confidence_trend if c > 0.8) / len(confidence_trend)
        }

        return {
            "total_decisions_analyzed": len(recent_decisions),
            "strategy_analysis": strategy_analysis,
            "time_analysis": time_analysis,
            "confidence_analysis": confidence_analysis,
            "analysis_timestamp": time.time()
        }

    def get_decision_details(self, game_id: str, turn_number: Optional[int] = None) -> List[Dict[str, Any]]:
        """è·å–ç‰¹å®šå†³ç­–çš„è¯¦ç»†ä¿¡æ¯"""
        decisions = []
        for record in self.decision_history:
            if record.game_id == game_id:
                if turn_number is None or record.turn_number == turn_number:
                    decisions.append(asdict(record))
        return decisions

    def export_debug_report(self, output_file: Optional[str] = None) -> str:
        """å¯¼å‡ºè°ƒè¯•æŠ¥å‘Š"""
        if output_file is None:
            timestamp = int(time.time())
            output_file = f"ai_debug_report_{timestamp}.json"

        report = {
            "session_info": {
                "start_time": self.current_session_start,
                "duration": time.time() - self.current_session_start,
                "total_decisions": len(self.decision_history)
            },
            "performance_metrics": asdict(self.performance_metrics),
            "decision_patterns": self.analyze_decision_patterns(),
            "recent_decisions": [asdict(record) for record in self.decision_history[-10:]],
            "export_timestamp": time.time()
        }

        output_path = Path(output_file)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        logger.info(f"ğŸ“Š è°ƒè¯•æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {output_path}")
        return str(output_path)

    def print_performance_summary(self):
        """æ‰“å°æ€§èƒ½æ‘˜è¦"""
        metrics = self.performance_metrics
        patterns = self.analyze_decision_patterns()

        print("\n" + "="*60)
        print("ğŸ” AIå†³ç­–æ€§èƒ½åˆ†ææŠ¥å‘Š")
        print("="*60)

        print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"   æ€»å†³ç­–æ•°: {metrics.total_decisions}")
        print(f"   æˆåŠŸå†³ç­–æ•°: {metrics.successful_decisions}")
        print(f"   å¹³å‡æ‰§è¡Œæ—¶é—´: {metrics.average_execution_time:.3f}ç§’")

        print(f"\nğŸ¯ ç½®ä¿¡åº¦åˆ†å¸ƒ:")
        for level, count in metrics.confidence_distribution.items():
            percentage = count / max(1, metrics.total_decisions) * 100
            print(f"   {level}: {count} ({percentage:.1f}%)")

        print(f"\nğŸ® åŠ¨ä½œç±»å‹åˆ†å¸ƒ:")
        for action_type, count in metrics.action_type_distribution.items():
            if count > 0:
                percentage = count / max(1, metrics.total_decisions) * 100
                print(f"   {action_type}: {count} ({percentage:.1f}%)")

        if "strategy_analysis" in patterns:
            print(f"\nğŸ§  ç­–ç•¥æ€§èƒ½åˆ†æ:")
            for strategy, stats in patterns["strategy_analysis"].items():
                print(f"   {strategy}:")
                print(f"     å†³ç­–æ•°: {stats['count']}")
                print(f"     å¹³å‡ç½®ä¿¡åº¦: {stats['avg_confidence']:.3f}")
                print(f"     å¹³å‡è€—æ—¶: {stats['avg_time']:.3f}ç§’")
                most_common = max(stats["common_actions"].items(), key=lambda x: x[1])
                print(f"     æœ€å¸¸ç”¨åŠ¨ä½œ: {most_common[0]} ({most_common[1]}æ¬¡)")

        print(f"\nğŸ“ˆ æœ€è¿‘è¶‹åŠ¿:")
        if "confidence_analysis" in patterns:
            conf_analysis = patterns["confidence_analysis"]
            print(f"   å¹³å‡ç½®ä¿¡åº¦: {conf_analysis['avg_confidence']:.3f}")
            print(f"   ç½®ä¿¡åº¦è¶‹åŠ¿: {conf_analysis['confidence_trend']}")
            print(f"   é«˜ç½®ä¿¡åº¦æ¯”ä¾‹: {conf_analysis['high_confidence_ratio']:.1%}")

        if "time_analysis" in patterns:
            time_analysis = patterns["time_analysis"]
            print(f"   å¹³å‡å†³ç­–æ—¶é—´: {time_analysis['avg_decision_time']:.3f}ç§’")

        print("\n" + "="*60)

    def clear_history(self):
        """æ¸…ç©ºå†³ç­–å†å²"""
        self.decision_history.clear()
        self.performance_metrics = PerformanceMetrics()
        self.current_session_start = time.time()
        logger.info("ğŸ—‘ï¸ è°ƒè¯•å†å²å·²æ¸…ç©º")

    def save_session(self, filename: Optional[str] = None):
        """ä¿å­˜å½“å‰è°ƒè¯•ä¼šè¯"""
        if filename is None:
            timestamp = int(time.time())
            filename = f"ai_debug_session_{timestamp}.json"

        session_data = {
            "session_start": self.current_session_start,
            "decision_history": [asdict(record) for record in self.decision_history],
            "performance_metrics": asdict(self.performance_metrics)
        }

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(session_data, f, indent=2, ensure_ascii=False)

        logger.info(f"ğŸ’¾ è°ƒè¯•ä¼šè¯å·²ä¿å­˜åˆ°: {filename}")

    def load_session(self, filename: str):
        """åŠ è½½è°ƒè¯•ä¼šè¯"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                session_data = json.load(f)

            self.current_session_start = session_data["session_start"]

            # é‡å»ºå†³ç­–å†å²
            self.decision_history.clear()
            for record_data in session_data["decision_history"]:
                record = DecisionRecord(**record_data)
                self.decision_history.append(record)

            # é‡å»ºæ€§èƒ½æŒ‡æ ‡
            metrics_data = session_data["performance_metrics"]
            self.performance_metrics = PerformanceMetrics(**metrics_data)

            logger.info(f"ğŸ“‚ è°ƒè¯•ä¼šè¯å·²ä» {filename} åŠ è½½")

        except Exception as e:
            logger.error(f"âŒ åŠ è½½è°ƒè¯•ä¼šè¯å¤±è´¥: {e}")


# å…¨å±€è°ƒè¯•å™¨å®ä¾‹
debugger = AIDebugger()