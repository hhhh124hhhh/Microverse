"""
æ··åˆAIå†³ç­–ç³»ç»Ÿ
ç»“åˆå¤šç§AIç­–ç•¥ï¼Œå®ç°æ›´æ™ºèƒ½å’Œé²æ£’çš„å†³ç­–
åŸºäºé›†æˆå­¦ä¹ çš„æ€æƒ³ï¼Œé‡‡ç”¨æŠ•ç¥¨å’Œæƒé‡æœºåˆ¶
"""
import asyncio
import time
import statistics
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import logging

from .base import AIStrategy, AIAction, ActionType, GameContext, AIStrategyError
from .rule_based import RuleBasedStrategy
from .llm_enhanced import LLMEnhancedStrategy


logger = logging.getLogger(__name__)


class ConsensusMethod(Enum):
    """å…±è¯†æ–¹æ³•æšä¸¾"""
    WEIGHTED_VOTING = "weighted_voting"  # åŠ æƒæŠ•ç¥¨
    MAJORITY_VOTING = "majority_voting"  # å¤šæ•°æŠ•ç¥¨
    CONFIDENCE_BASED = "confidence_based"  # åŸºäºç½®ä¿¡åº¦
    PERFORMANCE_BASED = "performance_based"  # åŸºäºå†å²æ€§èƒ½


@dataclass
class StrategyWeight:
    """ç­–ç•¥æƒé‡é…ç½®"""
    strategy_name: str
    weight: float
    min_confidence: float = 0.3
    max_votes: int = 1


@dataclass
class HybridDecision:
    """æ··åˆå†³ç­–ç»“æœ"""
    action: AIAction
    consensus_score: float  # å…±è¯†ç¨‹åº¦ 0-1
    participating_strategies: List[str]
    voting_details: Dict[str, Any]
    execution_time: float


class HybridAIStrategy(AIStrategy):
    """æ··åˆAIç­–ç•¥"""

    def __init__(self, name: str = "æ··åˆAI", config: Dict[str, Any] = None):
        default_config = {
            # ç­–ç•¥é…ç½® - å¹³è¡¡æƒé‡ï¼Œè®©LLMæœ‰æ›´å¤šè¯è¯­æƒ
            "strategies": [
                {"name": "rule_based", "weight": 0.55, "min_confidence": 0.15},  # é™ä½è§„åˆ™ç­–ç•¥æƒé‡ï¼Œé™ä½è¦æ±‚
                {"name": "llm_enhanced", "weight": 0.45, "min_confidence": 0.4}   # æé«˜LLMæƒé‡ï¼Œé™ä½è¦æ±‚
            ],

            # å…±è¯†æ–¹æ³•
            "consensus_method": ConsensusMethod.WEIGHTED_VOTING.value,

            # æ€§èƒ½é˜ˆå€¼
            "min_consensus_score": 0.15,  # è¿›ä¸€æ­¥é™ä½æœ€å°å…±è¯†åˆ†æ•°
            "max_decision_time": 25.0,    # å¢åŠ æœ€å¤§å†³ç­–æ—¶é—´ï¼Œç»™LLMæ›´å¤šæ—¶é—´

            # è‡ªé€‚åº”é…ç½®
            "enable_adaptive_weights": True,  # å¯ç”¨è‡ªé€‚åº”æƒé‡
            "performance_window": 10,         # å‡å°‘æ€§èƒ½è¯„ä¼°çª—å£ï¼Œæ›´å¿«é€‚åº”
            "weight_adjustment_factor": 0.2,  # æé«˜æƒé‡è°ƒæ•´å› å­ï¼Œæ›´å¿«è°ƒæ•´

            # å®¹é”™é…ç½®
            "fallback_strategy": "rule_based",
            "min_participating_strategies": 1,
            "enable_strategy_replacement": True,

            # ä¼˜åŒ–ï¼šLLMè¶…æ—¶å¤„ç†é…ç½®
            "llm_timeout_handling": "graceful_degradation",  # ä¼˜é›…é™çº§
            "llm_timeout_grace_period": 20.0,  # å¢åŠ LLMè¶…æ—¶å®½é™æœŸ
            "fallback_to_rules_on_timeout": True,  # è¶…æ—¶æ—¶ä¼˜å…ˆä½¿ç”¨è§„åˆ™ç­–ç•¥
            "prefer_cards_over_hero_power": True  # æ–°å¢ï¼šä¼˜å…ˆå‡ºç‰Œè€Œä¸æ˜¯è‹±é›„æŠ€èƒ½
        }

        if config:
            default_config.update(config)

        super().__init__(name, default_config)

        # åˆå§‹åŒ–å­ç­–ç•¥
        self.sub_strategies: Dict[str, AIStrategy] = {}
        self.strategy_weights: Dict[str, float] = {}
        self.strategy_performance: Dict[str, List[float]] = {}

        # ç»Ÿè®¡ä¿¡æ¯
        self.consensus_history: List[float] = []
        self.strategy_usage_count: Dict[str, int] = {}
        self.decisions_made = 0
        self.consensus_failures = 0

        # åˆå§‹åŒ–ç­–ç•¥
        self._initialize_strategies()

    def _initialize_strategies(self):
        """åˆå§‹åŒ–å­ç­–ç•¥"""
        for strategy_config in self.config["strategies"]:
            strategy_name = strategy_config["name"]
            weight = strategy_config["weight"]

            if strategy_name == "rule_based":
                strategy = RuleBasedStrategy(f"{self.name}_è§„åˆ™å±‚")
            elif strategy_name == "llm_enhanced":
                llm_config = self.config.get("llm_config", {})
                strategy = LLMEnhancedStrategy(f"{self.name}_LLMå±‚", llm_config)
            else:
                logger.warning(f"æœªçŸ¥ç­–ç•¥ç±»å‹: {strategy_name}")
                continue

            self.sub_strategies[strategy_name] = strategy
            self.strategy_weights[strategy_name] = weight
            self.strategy_performance[strategy_name] = []
            self.strategy_usage_count[strategy_name] = 0

            logger.info(f"åˆå§‹åŒ–å­ç­–ç•¥: {strategy_name}, æƒé‡: {weight}")

    def register_sub_strategy(self, name: str, strategy: AIStrategy, weight: float = 1.0):
        """æ³¨å†Œå­ç­–ç•¥"""
        self.sub_strategies[name] = strategy
        self.strategy_weights[name] = weight
        self.strategy_performance[name] = []
        self.strategy_usage_count[name] = 0
        logger.info(f"æ³¨å†Œå­ç­–ç•¥: {name}, æƒé‡: {weight}")

    def set_llm_manager(self, llm_manager):
        """è®¾ç½®LLMç®¡ç†å™¨"""
        for strategy in self.sub_strategies.values():
            if hasattr(strategy, 'set_llm_manager'):
                strategy.set_llm_manager(llm_manager)

    async def make_decision(self, context: GameContext) -> Optional[AIAction]:
        """
        ä½¿ç”¨æ··åˆç­–ç•¥åšå‡ºå†³ç­–
        """
        start_time = time.time()
        logger.info("ğŸ¯ æ··åˆAIå¼€å§‹å†³ç­–è¿‡ç¨‹...")

        try:
            # è·å–æ‰€æœ‰å­ç­–ç•¥çš„å†³ç­–
            logger.info("ğŸ“Š æ­¥éª¤1: æ”¶é›†å„ç­–ç•¥å†³ç­–...")
            strategy_decisions = await self._collect_strategy_decisions(context)

            if not strategy_decisions:
                logger.warning("âŒ æ²¡æœ‰ç­–ç•¥è¿”å›æœ‰æ•ˆå†³ç­–ï¼Œä½¿ç”¨å›é€€ç­–ç•¥")
                return await self._fallback_decision(context)

            # æ˜¾ç¤ºæ”¶é›†åˆ°çš„å†³ç­–
            logger.info(f"âœ… æ”¶é›†åˆ° {len(strategy_decisions)} ä¸ªç­–ç•¥å†³ç­–:")
            for strategy_name, action in strategy_decisions:
                logger.info(f"   - {strategy_name}: {action.action_type.value} (ç½®ä¿¡åº¦: {action.confidence:.2f})")

            # ç”Ÿæˆæ··åˆå†³ç­–
            logger.info("ğŸ”„ æ­¥éª¤2: ç”Ÿæˆæ··åˆå†³ç­–...")
            hybrid_decision = await self._generate_hybrid_decision(strategy_decisions, context)

            # éªŒè¯å†³ç­–è´¨é‡
            logger.info("âœ”ï¸ æ­¥éª¤3: éªŒè¯å†³ç­–è´¨é‡...")
            if not self._validate_decision(hybrid_decision):
                logger.warning(f"âŒ æ··åˆå†³ç­–æœªé€šè¿‡éªŒè¯ (å…±è¯†åˆ†æ•°: {hybrid_decision.consensus_score:.2f})ï¼Œä½¿ç”¨å›é€€ç­–ç•¥")
                return await self._fallback_decision(context)

            # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
            execution_time = time.time() - start_time
            self._update_performance_stats(hybrid_decision, execution_time)

            # è‡ªé€‚åº”è°ƒæ•´æƒé‡
            if self.config["enable_adaptive_weights"]:
                logger.info("ğŸ”§ æ­¥éª¤4: è‡ªé€‚åº”è°ƒæ•´æƒé‡...")
                self._adaptive_weight_adjustment(hybrid_decision)

            self.decisions_made += 1
            logger.info(f"ğŸ‰ æ··åˆAIå†³ç­–å®Œæˆ: {hybrid_decision.action.action_type.value}, "
                      f"å…±è¯†åˆ†æ•°: {hybrid_decision.consensus_score:.2f}, "
                      f"è€—æ—¶: {hybrid_decision.execution_time:.3f}s")
            logger.info(f"ğŸ’­ æ¨ç†è¿‡ç¨‹: {hybrid_decision.action.reasoning}")

            # æ˜¾ç¤ºå‚ä¸å†³ç­–çš„ç­–ç•¥
            if hybrid_decision.participating_strategies:
                logger.info(f"ğŸ‘¥ å‚ä¸ç­–ç•¥: {', '.join(hybrid_decision.participating_strategies)}")

            return hybrid_decision.action

        except Exception as e:
            logger.error(f"ğŸ’¥ æ··åˆAIå†³ç­–å¤±è´¥: {e}")
            self.consensus_failures += 1
            return await self._fallback_decision(context)

    async def _collect_strategy_decisions(self, context: GameContext) -> List[Tuple[str, AIAction]]:
        """æ”¶é›†æ‰€æœ‰å­ç­–ç•¥çš„å†³ç­–"""
        decisions = []
        tasks = []

        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ç­–ç•¥
        for strategy_name, strategy in self.sub_strategies.items():
            if strategy.can_handle_context(context):
                task = asyncio.create_task(
                    self._execute_strategy_with_timeout(strategy, strategy_name, context)
                )
                tasks.append(task)

        # ç­‰å¾…æ‰€æœ‰ç­–ç•¥å®Œæˆ
        if tasks:
            results = await asyncio.gather(*tasks, return_exceptions=True)

            for result in results:
                if isinstance(result, tuple) and result[0] and result[1]:
                    decisions.append(result)
                elif isinstance(result, Exception):
                    logger.error(f"ç­–ç•¥æ‰§è¡Œå¼‚å¸¸: {result}")

        return decisions

    async def _execute_strategy_with_timeout(self, strategy: AIStrategy,
                                          strategy_name: str,
                                          context: GameContext) -> Tuple[str, Optional[AIAction]]:
        """å¸¦è¶…æ—¶çš„ç­–ç•¥æ‰§è¡Œ"""
        try:
            # æ ¹æ®é…ç½®åŠ¨æ€è®¾ç½®è¶…æ—¶æ—¶é—´
            if strategy_name == "llm_enhanced":
                timeout = self.config.get("llm_timeout_grace_period", 15.0)
                logger.info(f"ğŸ§  æ‰§è¡ŒLLMå¢å¼ºç­–ç•¥ï¼ˆè¶…æ—¶: {timeout}ç§’ï¼‰...")
            else:
                timeout = 6.0  # è§„åˆ™ç­–ç•¥ç»™6ç§’ï¼Œç¨å¾®å¢åŠ ä½†ä¿æŒå“åº”æ€§
                logger.info(f"ğŸ“‹ æ‰§è¡Œè§„åˆ™ç­–ç•¥ï¼ˆè¶…æ—¶: {timeout}ç§’ï¼‰...")

            action = await asyncio.wait_for(
                strategy.execute_with_timing(context),
                timeout=timeout
            )

            if action:
                self.strategy_usage_count[strategy_name] += 1
                logger.info(f"âœ… ç­–ç•¥ {strategy_name} å†³ç­–å®Œæˆ: {action.action_type.value}, "
                          f"ç½®ä¿¡åº¦: {action.confidence:.2f}, è€—æ—¶: {action.execution_time:.3f}s")
                return strategy_name, action
            else:
                logger.warning(f"âŒ ç­–ç•¥ {strategy_name} æ— æ³•åšå‡ºå†³ç­–")

        except asyncio.TimeoutError:
            logger.warning(f"â° ç­–ç•¥ {strategy_name} æ‰§è¡Œè¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")

            # LLMç­–ç•¥è¶…æ—¶æ—¶çš„ç‰¹æ®Šå¤„ç†
            if strategy_name == "llm_enhanced" and self.config.get("fallback_to_rules_on_timeout", True):
                logger.info("ğŸ”„ LLMç­–ç•¥è¶…æ—¶ï¼Œå¯åŠ¨ä¼˜é›…é™çº§æœºåˆ¶...")
                # ç«‹å³æ‰§è¡Œè§„åˆ™ç­–ç•¥ä½œä¸ºå›é€€
                if "rule_based" in self.sub_strategies:
                    try:
                        rule_strategy = self.sub_strategies["rule_based"]
                        fallback_action = await asyncio.wait_for(
                            rule_strategy.execute_with_timing(context),
                            timeout=3.0
                        )
                        if fallback_action:
                            logger.info(f"ğŸ›¡ï¸ è§„åˆ™ç­–ç•¥å›é€€æˆåŠŸ: {fallback_action.action_type.value}")
                            return "rule_based_fallback", fallback_action
                    except Exception as fallback_error:
                        logger.error(f"å›é€€è§„åˆ™ç­–ç•¥ä¹Ÿå¤±è´¥: {fallback_error}")

        except Exception as e:
            logger.error(f"ğŸ’¥ ç­–ç•¥ {strategy_name} æ‰§è¡Œå¤±è´¥: {e}")

        return strategy_name, None

    async def _generate_hybrid_decision(self, strategy_decisions: List[Tuple[str, AIAction]],
                                      context: GameContext) -> HybridDecision:
        """ç”Ÿæˆæ··åˆå†³ç­–"""
        consensus_method = ConsensusMethod(self.config["consensus_method"])

        if consensus_method == ConsensusMethod.WEIGHTED_VOTING:
            return self._weighted_voting_decision(strategy_decisions, context)
        elif consensus_method == ConsensusMethod.MAJORITY_VOTING:
            return self._majority_voting_decision(strategy_decisions, context)
        elif consensus_method == ConsensusMethod.CONFIDENCE_BASED:
            return self._confidence_based_decision(strategy_decisions, context)
        elif consensus_method == ConsensusMethod.PERFORMANCE_BASED:
            return self._performance_based_decision(strategy_decisions, context)
        else:
            return self._weighted_voting_decision(strategy_decisions, context)

    def _weighted_voting_decision(self, strategy_decisions: List[Tuple[str, AIAction]],
                                context: GameContext) -> HybridDecision:
        """åŠ æƒæŠ•ç¥¨å†³ç­–"""
        # æŒ‰åŠ¨ä½œç±»å‹åˆ†ç»„
        action_groups = {}
        for strategy_name, action in strategy_decisions:
            action_type = action.action_type
            if action_type not in action_groups:
                action_groups[action_type] = []
            action_groups[action_type].append((strategy_name, action))

        # è®¡ç®—æ¯ä¸ªåŠ¨ä½œç»„çš„åŠ æƒåˆ†æ•°
        best_action = None
        best_score = -1
        best_details = {}

        for action_type, actions in action_groups.items():
            total_weight = 0
            total_confidence = 0
            participating_strategies = []

            for strategy_name, action in actions:
                weight = self.strategy_weights.get(strategy_name, 1.0)
                confidence = action.confidence

                # åº”ç”¨å‡ºç‰Œä¼˜å…ˆç­–ç•¥
                if self.config.get("prefer_cards_over_hero_power", False):
                    if action_type == ActionType.PLAY_CARD:
                        # åœ¨å‡ºç‰Œå’Œè‹±é›„æŠ€èƒ½ä¹‹é—´é€‰æ‹©æ—¶ï¼Œä¼˜å…ˆå‡ºç‰Œ
                        confidence *= 1.3  # ç»™å‡ºç‰Œ30%çš„åŠ æˆ
                    elif action_type == ActionType.USE_HERO_POWER:
                        # å¦‚æœæœ‰å‡ºç‰Œé€‰é¡¹ï¼Œé™ä½è‹±é›„æŠ€èƒ½ä¼˜å…ˆçº§
                        if ActionType.PLAY_CARD in action_groups:
                            confidence *= 0.7  # ç»™è‹±é›„æŠ€èƒ½30%çš„æƒ©ç½š

                total_weight += weight
                total_confidence += weight * confidence
                participating_strategies.append(strategy_name)

            # å¹³å‡ç½®ä¿¡åº¦
            avg_confidence = total_confidence / max(1, total_weight)

            if avg_confidence > best_score:
                best_score = avg_confidence
                # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„åŠ¨ä½œä½œä¸ºä»£è¡¨
                best_action = max(actions, key=lambda x: x[1].confidence)[1]
                best_details = {
                    "method": "weighted_voting",
                    "total_weight": total_weight,
                    "avg_confidence": avg_confidence,
                    "action_count": len(actions),
                    "prefer_cards": self.config.get("prefer_cards_over_hero_power", False)
                }

        # è®¡ç®—å…±è¯†åˆ†æ•°
        consensus_score = self._calculate_consensus_score(strategy_decisions, best_action)

        return HybridDecision(
            action=best_action or AIAction(ActionType.END_TURN, 0.5, "æ— æœ‰æ•ˆå†³ç­–", {}),
            consensus_score=consensus_score,
            participating_strategies=[s[0] for s in strategy_decisions],
            voting_details=best_details,
            execution_time=0.0
        )

    def _majority_voting_decision(self, strategy_decisions: List[Tuple[str, AIAction]],
                                context: GameContext) -> HybridDecision:
        """å¤šæ•°æŠ•ç¥¨å†³ç­–"""
        # ç»Ÿè®¡æ¯ä¸ªåŠ¨ä½œç±»å‹çš„æŠ•ç¥¨æ•°
        action_votes = {}
        for strategy_name, action in strategy_decisions:
            action_type = action.action_type
            if action_type not in action_votes:
                action_votes[action_type] = []
            action_votes[action_type].append((strategy_name, action))

        # æ‰¾åˆ°æŠ•ç¥¨æ•°æœ€å¤šçš„åŠ¨ä½œç±»å‹
        if not action_votes:
            best_action_type = ActionType.END_TURN
            best_actions = []
        else:
            best_action_type = max(action_votes.keys(), key=lambda x: len(action_votes[x]))
            best_actions = action_votes[best_action_type]

        # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„åŠ¨ä½œ
        best_action = max(best_actions, key=lambda x: x[1].confidence)[1] if best_actions else None

        # è®¡ç®—å…±è¯†åˆ†æ•°ï¼ˆåŸºäºæŠ•ç¥¨æ¯”ä¾‹ï¼‰
        total_votes = len(strategy_decisions)
        majority_votes = len(best_actions)
        consensus_score = majority_votes / max(1, total_votes)

        voting_details = {
            "method": "majority_voting",
            "total_votes": total_votes,
            "majority_votes": majority_votes,
            "winning_action_type": best_action_type.value
        }

        return HybridDecision(
            action=best_action or AIAction(ActionType.END_TURN, 0.5, "æ— æœ‰æ•ˆå†³ç­–", {}),
            consensus_score=consensus_score,
            participating_strategies=[s[0] for s in strategy_decisions],
            voting_details=voting_details,
            execution_time=0.0
        )

    def _confidence_based_decision(self, strategy_decisions: List[Tuple[str, AIAction]],
                                 context: GameContext) -> HybridDecision:
        """åŸºäºç½®ä¿¡åº¦çš„å†³ç­–"""
        if not strategy_decisions:
            best_action = AIAction(ActionType.END_TURN, 0.5, "æ— æœ‰æ•ˆå†³ç­–", {})
            consensus_score = 0.0
        else:
            # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„åŠ¨ä½œ
            best_strategy, best_action = max(strategy_decisions, key=lambda x: x[1].confidence)
            consensus_score = best_action.confidence

        voting_details = {
            "method": "confidence_based",
            "best_strategy": best_strategy if strategy_decisions else None,
            "confidence": consensus_score
        }

        return HybridDecision(
            action=best_action,
            consensus_score=consensus_score,
            participating_strategies=[s[0] for s in strategy_decisions],
            voting_details=voting_details,
            execution_time=0.0
        )

    def _performance_based_decision(self, strategy_decisions: List[Tuple[str, AIAction]],
                                  context: GameContext) -> HybridDecision:
        """åŸºäºå†å²æ€§èƒ½çš„å†³ç­–"""
        # è®¡ç®—æ¯ä¸ªç­–ç•¥çš„æ€§èƒ½åŠ æƒåˆ†æ•°
        scored_decisions = []
        for strategy_name, action in strategy_decisions:
            performance_score = self._calculate_strategy_performance(strategy_name)
            weighted_confidence = action.confidence * performance_score
            scored_decisions.append((weighted_confidence, strategy_name, action))

        if not scored_decisions:
            best_action = AIAction(ActionType.END_TURN, 0.5, "æ— æœ‰æ•ˆå†³ç­–", {})
            consensus_score = 0.0
        else:
            # é€‰æ‹©æ€§èƒ½åŠ æƒåˆ†æ•°æœ€é«˜çš„åŠ¨ä½œ
            _, best_strategy, best_action = max(scored_decisions, key=lambda x: x[0])
            consensus_score = best_action.confidence

        voting_details = {
            "method": "performance_based",
            "best_strategy": best_strategy if scored_decisions else None,
            "performance_weighted_score": max([s[0] for s in scored_decisions]) if scored_decisions else 0
        }

        return HybridDecision(
            action=best_action,
            consensus_score=consensus_score,
            participating_strategies=[s[0] for s in strategy_decisions],
            voting_details=voting_details,
            execution_time=0.0
        )

    def _calculate_consensus_score(self, strategy_decisions: List[Tuple[str, AIAction]],
                                 selected_action: AIAction) -> float:
        """è®¡ç®—å…±è¯†åˆ†æ•°"""
        if not strategy_decisions:
            return 0.0

        # è®¡ç®—åŠ¨ä½œç±»å‹çš„ä¸€è‡´æ€§
        action_types = [action.action_type for _, action in strategy_decisions]
        selected_type = selected_action.action_type

        type_agreement = sum(1 for at in action_types if at == selected_type) / len(action_types)

        # è®¡ç®—ç½®ä¿¡åº¦çš„ä¸€è‡´æ€§
        confidences = [action.confidence for _, action in strategy_decisions]
        confidence_variance = statistics.variance(confidences) if len(confidences) > 1 else 0
        confidence_agreement = 1 - min(1, confidence_variance * 4)  # æ–¹å·®è¶Šå°ï¼Œä¸€è‡´æ€§è¶Šé«˜

        # ç»¼åˆå…±è¯†åˆ†æ•°
        consensus_score = (type_agreement * 0.7 + confidence_agreement * 0.3)

        return max(0, min(1, consensus_score))

    def _calculate_strategy_performance(self, strategy_name: str) -> float:
        """è®¡ç®—ç­–ç•¥å†å²æ€§èƒ½åˆ†æ•°"""
        if strategy_name not in self.strategy_performance:
            return 1.0

        performances = self.strategy_performance[strategy_name]
        if not performances:
            return 1.0

        # ä½¿ç”¨æœ€è¿‘çš„æ€§èƒ½æ•°æ®
        window_size = min(self.config["performance_window"], len(performances))
        recent_performances = performances[-window_size:]

        # è®¡ç®—å¹³å‡æ€§èƒ½
        avg_performance = sum(recent_performances) / len(recent_performances)

        # æ˜ å°„åˆ°æƒé‡ç³»æ•° (0.1 - 2.0)
        weight_factor = 0.1 + (avg_performance * 1.9)

        return weight_factor

    def _validate_decision(self, hybrid_decision: HybridDecision) -> bool:
        """éªŒè¯å†³ç­–è´¨é‡"""
        # æ£€æŸ¥å…±è¯†åˆ†æ•°é˜ˆå€¼
        if hybrid_decision.consensus_score < self.config["min_consensus_score"]:
            return False

        # æ£€æŸ¥å‚ä¸ç­–ç•¥æ•°é‡
        if len(hybrid_decision.participating_strategies) < self.config["min_participating_strategies"]:
            return False

        # æ£€æŸ¥åŠ¨ä½œæœ‰æ•ˆæ€§
        if not hybrid_decision.action or hybrid_decision.action.confidence < 0.1:
            return False

        return True

    async def _fallback_decision(self, context: GameContext) -> Optional[AIAction]:
        """å›é€€å†³ç­–ç­–ç•¥"""
        fallback_name = self.config["fallback_strategy"]
        if fallback_name in self.sub_strategies:
            try:
                fallback_strategy = self.sub_strategies[fallback_name]
                action = await fallback_strategy.execute_with_timing(context)
                logger.info(f"ä½¿ç”¨å›é€€ç­–ç•¥: {fallback_name}")
                return action
            except Exception as e:
                logger.error(f"å›é€€ç­–ç•¥ä¹Ÿå¤±è´¥: {e}")

        # æœ€åçš„ä¿é™©ï¼šç»“æŸå›åˆ
        return AIAction(
            action_type=ActionType.END_TURN,
            confidence=0.3,
            reasoning="æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥ï¼Œç»“æŸå›åˆ",
            parameters={}
        )

    def _update_performance_stats(self, hybrid_decision: HybridDecision, execution_time: float):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        hybrid_decision.execution_time = execution_time
        self.consensus_history.append(hybrid_decision.consensus_score)

        # é™åˆ¶å†å²è®°å½•é•¿åº¦
        if len(self.consensus_history) > 1000:
            self.consensus_history = self.consensus_history[-500:]

    def _adaptive_weight_adjustment(self, hybrid_decision: HybridDecision):
        """è‡ªé€‚åº”æƒé‡è°ƒæ•´"""
        if not self.config["enable_adaptive_weights"]:
            return

        # è¿™é‡Œå¯ä»¥æ ¹æ®å†³ç­–ç»“æœè°ƒæ•´ç­–ç•¥æƒé‡
        # ç®€åŒ–å®ç°ï¼šåŸºäºå…±è¯†åˆ†æ•°è°ƒæ•´
        adjustment_factor = self.config["weight_adjustment_factor"]

        for strategy_name in hybrid_decision.participating_strategies:
            if strategy_name in self.strategy_weights:
                # æ ¹æ®å…±è¯†è´¨é‡è°ƒæ•´æƒé‡
                weight_adjustment = adjustment_factor * hybrid_decision.consensus_score
                self.strategy_weights[strategy_name] *= (1 + weight_adjustment)

        # å½’ä¸€åŒ–æƒé‡
        total_weight = sum(self.strategy_weights.values())
        if total_weight > 0:
            for strategy_name in self.strategy_weights:
                self.strategy_weights[strategy_name] /= total_weight

    def evaluate_board_state(self, context: GameContext) -> float:
        """è¯„ä¼°å±€é¢çŠ¶æ€ï¼ˆä½¿ç”¨åŠ æƒå¹³å‡ï¼‰"""
        if not self.sub_strategies:
            return 0.0

        scores = []
        weights = []

        for strategy_name, strategy in self.sub_strategies.items():
            try:
                score = strategy.evaluate_board_state(context)
                weight = self.strategy_weights.get(strategy_name, 1.0)
                scores.append(score)
                weights.append(weight)
            except Exception as e:
                logger.warning(f"ç­–ç•¥ {strategy_name} è¯„ä¼°å±€é¢å¤±è´¥: {e}")

        if not scores:
            return 0.0

        # åŠ æƒå¹³å‡
        weighted_sum = sum(s * w for s, w in zip(scores, weights))
        total_weight = sum(weights)

        return weighted_sum / max(1, total_weight)

    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        base_stats = super().get_performance_stats()

        # æ·»åŠ æ··åˆç­–ç•¥ç‰¹æœ‰çš„ç»Ÿè®¡
        hybrid_stats = {
            "decisions_made": self.decisions_made,
            "consensus_failures": self.consensus_failures,
            "average_consensus_score": sum(self.consensus_history) / max(1, len(self.consensus_history)),
            "consensus_score_distribution": {
                "excellent": sum(1 for s in self.consensus_history if s > 0.8),
                "good": sum(1 for s in self.consensus_history if 0.6 < s <= 0.8),
                "fair": sum(1 for s in self.consensus_history if 0.4 < s <= 0.6),
                "poor": sum(1 for s in self.consensus_history if s <= 0.4)
            },
            "strategy_weights": self.strategy_weights.copy(),
            "strategy_usage_count": self.strategy_usage_count.copy()
        }

        # æ·»åŠ å­ç­–ç•¥ç»Ÿè®¡
        sub_strategy_stats = {}
        for name, strategy in self.sub_strategies.items():
            sub_strategy_stats[name] = strategy.get_performance_stats()

        hybrid_stats["sub_strategies"] = sub_strategy_stats
        base_stats.update(hybrid_stats)

        return base_stats

    def reset_statistics(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        super().reset_statistics()
        self.consensus_history.clear()
        self.decisions_made = 0
        self.consensus_failures = 0

        for strategy in self.sub_strategies.values():
            strategy.reset_statistics()

        for count_key in self.strategy_usage_count:
            self.strategy_usage_count[count_key] = 0